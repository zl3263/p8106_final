---
title: "p8106_final"
author: "Zekai Jin, Zizhao Lin, Jiawen Zhao"
date: "2023-4-30"
output: html_document
---


```{r, echo=FALSE}
knitr::opts_chunk$set(
  message  = FALSE,
  warning = FALSE
)
```


```{r}
# Load the packages
library(tidyverse)
library(forcats)
library(ggridges)
library(corrplot)
library(patchwork)
library(caret)
library(ISLR)
library(mlbench)
library(caret)
library(rpart)
library(rpart.plot)
library(party)
library(partykit)
library(pROC)
library(randomForest)
library(ranger)
library(gbm)
```

### Intro

# For this project, we are using a public dataset combining 3 cohort studies regarding COVID-19 recovery information, to gain a better understanding of the factors that predict recovery time from COVID-19 illness. This dataset includes 15 variables, they are age, gender, race, smoking, height, weight, BMI, hypertension, diabetes, sbp, ldl, vaccine, severity, study, and recovery time, where the recovery time is the dependent variable that we want to predict, and the rest 14 variables are predictors that help us to build models predicting the recovery time. Here, we set recovery time as a binary variable taking values of 'f' and 's', where 'f' represents recovering within with equal 30 days and 's' represtns recoverying longer than 30 days. Among those predictors, there are 8 categorical variables, and 6 continuous variables. In the following sections, we are going to build models, including glm, classification tree, regression tree, svm, to best predict our binary response variable, recovery time.


# prepare the dataset

```{r}
load("data/recovery.RData")

# sample from data
set.seed(2357) 
sample_1=sample(1:10000, 2000)
set.seed(3263) 
sample_2=sample(1:10000, 2000)

sample = c(sample_1,sample_2) %>% unique()

set.seed(1)

# preprocessing
dat = 
  dat[sample,] %>%
  janitor::clean_names() %>%
  mutate(
    gender=fct_recode(factor(gender),male='1',female='0'),
    race=fct_recode(factor(race),white='1',asian='2',black='3',hispanic='4'),
    smoking=fct_recode(factor(smoking),never='0',former='1',current='2'),
    hypertension=factor(hypertension),
    diabetes=factor(diabetes),
    vaccine=factor(vaccine),
    severity=factor(severity),
    study=factor(study),
    recovery_bin = if_else(recovery_time <= 30, 'f', 's'), 
    recovery_bin = factor(recovery_bin),
  ) %>%
  select(-id, -recovery_time)


# train-test splitting
sample = sample(c(TRUE, FALSE), nrow(dat), replace=TRUE, prob=c(0.8,0.2))
data_train = dat[sample,]
data_test = dat[!sample,]


```


## bagging
```{r}
set.seed(1)
bagging <- randomForest(recovery_bin ~ . ,
                        data_train,
                        mtry = 14)
bagging
```

bagging - Here's we choose mtry to be 14, since there are 14 potential predictors in our model. 
The OOB estimate of the error rate is 30.83%, which is an estimate of the classification error rate of the model when applied to new data. The confusion matrix shows the number of true negatives (284), false positives (589), false negatives (288), and true positives (1684) in the predictions made by the model on the OOB samples.
The class.error is the classification error rate, which is the proportion of misclassified cases. The error rate for classifying "f" is 0.6746850 and for "s" it is 0.1460446.
In summary, the model has a moderate OOB error rate of 30.83%, with more errors in classifying "f" than "s".


## Boosting

```{r}
### Boosting
dat2 <- dat
dat2$recovery_bin <- as.numeric(dat$recovery_bin == "f")
set.seed(1)
bst <- gbm(recovery_bin ~ . ,
           dat2[sample,],
           distribution = "adaboost",
           n.trees = 2000,
           interaction.depth = 2,
           shrinkage = 0.005,
           cv.folds = 5,
           n.cores = 2)
gbm.perf(bst, method = "cv")

```

The plot shows the cross-validation performance of the GBM (Gradient Boosting Machine) model on the training data. The x-axis represents the number of boosting iterations, and the y-axis represents the model's performance metric. The plot shows the performance on the training data (black line) and the performance on the test data (green line) for each boosting iteration, and the blue dashed line shows what is the optimal number of iterations = 1866.





## cart

```{r}
ctrl <- trainControl(method = "cv", 
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
set.seed(1)
rpart.fit <- train(recovery_bin ~ . ,
                   data = dat,
                   subset = sample,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-10,-2, len = 50))),
                   trControl = ctrl,
                   metric = "ROC")
ggplot(rpart.fit, highlight = TRUE)

rpart.fit$bestTune
rpart.plot(rpart.fit$finalModel)
```

The optimal value of cp is 0.00843378, which is the value of the complexity parameter that results in the best performance of the model. Here, the cp controls the complexity of the tree, with smaller values of cp resulting in larger trees and larger values of cp resulting in smaller trees with fewer splits.

From the plot, we see that the tree with size of 7 has the highest ROC.

## cit
```{r}
set.seed(1)
ctree.fit <- train(recovery_bin ~ . , 
                   dat,
                   subset = sample,
                   method = "ctree",
                   tuneGrid = data.frame(mincriterion = 1-exp(seq(-5, -1, length = 50))),
                   metric = "ROC",
                   trControl = ctrl)
ggplot(ctree.fit, highlight = TRUE)
plot(ctree.fit$finalModel)

ctree.fit$bestTune
```

The optimal value of cp is 0.7922518, which is the value of the complexity parameter that results in the best performance of the model, and this model has ROC of 0.693.


## compare two trees
```{r}
summary(resamples(list(rpart.fit, ctree.fit)))
```

Since ctree.fit model has larger ROC, it's a better classification tree compared to the rpart.fit. 

